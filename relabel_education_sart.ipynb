{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relabel Education and SART Videos\n",
    "\n",
    "This notebook creates label files for Education and SART tasks by:\n",
    "1. Reading annotation CSVs from preprocessed subjects\n",
    "2. Identifying Education (position 3) and SART segments (position 4 + large unlabeled)\n",
    "3. Copying corresponding acq files as label files\n",
    "\n",
    "**Input**: `ELM_preprocessed/sub-*/` folders with annotations and acq files  \n",
    "**Output**: New label files (`label-Education`, `label-SART-practice`, `label-SART-actual`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup and Configuration\nimport pandas as pd\nfrom pathlib import Path\nimport shutil\n\n# Configuration\nbase_dir = Path(\"/Users/saewonchung/Desktop/ELM_MW_data_analysis\")\npreprocessed_dir = base_dir / \"ELM_preprocessed\"\n\n# Education video durations (5 different videos, randomly selected per subject)\nEDUCATION_DURATIONS = [376, 314, 326, 385, 319]\nDURATION_TOLERANCE = 5\n\n# DRY RUN MODE: Set to True to test without creating files\nDRY_RUN = True  # Change to False to actually create label files\n\nprint(f\"Base directory: {base_dir}\")\nprint(f\"Preprocessed directory: {preprocessed_dir}\")\nprint(f\"Education durations: {EDUCATION_DURATIONS} ¬±{DURATION_TOLERANCE}s\")\nprint(f\"\\n{'üîç DRY RUN MODE' if DRY_RUN else '‚úÖ PRODUCTION MODE'} - Files will {'NOT' if DRY_RUN else ''} be created\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def identify_education_sart(annotations_df):\n",
    "    \"\"\"\n",
    "    Identify Education and SART segments from annotations.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys: 'education_duration', 'sart_practice_duration', 'warnings'\n",
    "    \"\"\"\n",
    "    # Filter meaningful Video/Begin events (duration > 1s)\n",
    "    video_begin = annotations_df[\n",
    "        (annotations_df['description'].str.contains('Video/Begin')) &\n",
    "        (annotations_df['duration'] > 1)\n",
    "    ].copy()\n",
    "\n",
    "    video_begin = video_begin.reset_index(drop=True)\n",
    "\n",
    "    result = {\n",
    "        'education_duration': None,\n",
    "        'sart_practice_duration': None,\n",
    "        'warnings': []\n",
    "    }\n",
    "\n",
    "    # Position 3: Education (0-indexed = position 2)\n",
    "    if len(video_begin) >= 3:\n",
    "        edu_duration = int(video_begin.iloc[2]['duration'])\n",
    "\n",
    "        # Check if duration matches any education video\n",
    "        matched = False\n",
    "        for target_dur in EDUCATION_DURATIONS:\n",
    "            if abs(edu_duration - target_dur) <= DURATION_TOLERANCE:\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            result['warnings'].append(\n",
    "                f\"Education duration {edu_duration}s doesn't match known videos {EDUCATION_DURATIONS}\"\n",
    "            )\n",
    "\n",
    "        result['education_duration'] = edu_duration\n",
    "    else:\n",
    "        result['warnings'].append(f\"Incomplete data: only {len(video_begin)} meaningful Video/Begin events\")\n",
    "\n",
    "    # Position 4: SART practice (0-indexed = position 3)\n",
    "    if len(video_begin) >= 4:\n",
    "        sart_practice_dur = int(video_begin.iloc[3]['duration'])\n",
    "\n",
    "        if not (30 <= sart_practice_dur <= 110):\n",
    "            result['warnings'].append(\n",
    "                f\"SART practice duration {sart_practice_dur}s outside expected range [30-110]s\"\n",
    "            )\n",
    "\n",
    "        result['sart_practice_duration'] = sart_practice_dur\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def find_acq_file_by_duration(subject_dir, target_duration, tolerance=2):\n",
    "    \"\"\"\n",
    "    Find acq file matching the target duration.\n",
    "\n",
    "    Args:\n",
    "        subject_dir: Path to subject's preprocessed folder\n",
    "        target_duration: Target duration in seconds\n",
    "        tolerance: Duration matching tolerance\n",
    "\n",
    "    Returns:\n",
    "        Path to matching acq file, or None\n",
    "    \"\"\"\n",
    "    acq_files = list(subject_dir.glob(\"*_acq-*_dur-*_desc-preproc_haemo.csv\"))\n",
    "\n",
    "    for acq_file in acq_files:\n",
    "        # Parse duration from filename: acq-8_dur-375_desc-preproc_haemo.csv\n",
    "        parts = acq_file.stem.split('_')\n",
    "        for part in parts:\n",
    "            if part.startswith('dur-'):\n",
    "                file_duration = int(part.split('-')[1])\n",
    "                if abs(file_duration - target_duration) <= tolerance:\n",
    "                    return acq_file\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_large_unlabeled_acq_files(subject_dir, min_duration=500):\n",
    "    \"\"\"\n",
    "    Find large acq files (>500s) that are unlabeled (potential SART actual).\n",
    "\n",
    "    Returns:\n",
    "        List of paths to large unlabeled acq files\n",
    "    \"\"\"\n",
    "    acq_files = list(subject_dir.glob(\"*_acq-*_dur-*_desc-preproc_haemo.csv\"))\n",
    "    large_files = []\n",
    "\n",
    "    # Get list of already labeled durations (from existing label files)\n",
    "    labeled_durations = set()\n",
    "    for label_file in subject_dir.glob(\"*_label-*_haemo.csv\"):\n",
    "        # Try to infer duration from the data if needed\n",
    "        # For now, we'll check Zima (~508s) and Splitscreen (~145s)\n",
    "        if 'Zima' in label_file.name:\n",
    "            labeled_durations.add(508)\n",
    "        elif 'Splitscreen' in label_file.name:\n",
    "            labeled_durations.add(145)\n",
    "\n",
    "    for acq_file in acq_files:\n",
    "        # Parse duration from filename\n",
    "        parts = acq_file.stem.split('_')\n",
    "        for part in parts:\n",
    "            if part.startswith('dur-'):\n",
    "                file_duration = int(part.split('-')[1])\n",
    "\n",
    "                # Check if large and not already labeled\n",
    "                if file_duration > min_duration:\n",
    "                    # Check if this duration is close to any labeled duration\n",
    "                    is_labeled = any(abs(file_duration - ld) <= 10 for ld in labeled_durations)\n",
    "                    if not is_labeled:\n",
    "                        large_files.append(acq_file)\n",
    "                break\n",
    "\n",
    "    return large_files\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Process All Subjects\n\ndef process_subject(subject_dir):\n    \"\"\"Process a single subject and create Education/SART label files.\"\"\"\n    subject_name = subject_dir.name\n    print(f\"\\n{'='*60}\")\n    print(f\"Processing {subject_name}\")\n    print(f\"{'='*60}\")\n\n    # Find annotation file\n    annot_files = list(subject_dir.glob(\"*_annotations.csv\"))\n    if not annot_files:\n        print(f\"‚ö†Ô∏è  No annotation file found, skipping\")\n        return {'subject': subject_name, 'status': 'no_annotations', \n                'education_created': False, 'sart_practice_created': False, \n                'sart_actual_created': False, 'warnings': []}\n\n    annot_file = annot_files[0]\n    annotations = pd.read_csv(annot_file)\n\n    # Identify Education and SART segments\n    result = identify_education_sart(annotations)\n\n    # Print warnings\n    for warning in result['warnings']:\n        print(f\"‚ö†Ô∏è  {warning}\")\n\n    status = {\n        'subject': subject_name,\n        'education_created': False,\n        'sart_practice_created': False,\n        'sart_actual_created': False,\n        'warnings': result['warnings']\n    }\n\n    # Create Education label file\n    if result['education_duration']:\n        edu_acq = find_acq_file_by_duration(subject_dir, result['education_duration'])\n        if edu_acq:\n            # Create label filename\n            session_id = edu_acq.stem.split('_ses-')[1].split('_')[0]\n            label_file = subject_dir / f\"{subject_name}_ses-{session_id}_task-Video_label-Education_haemo.csv\"\n\n            # Copy acq file to label file (or simulate in dry run)\n            if DRY_RUN:\n                print(f\"üîç [DRY RUN] Would create: {label_file.name} (duration={result['education_duration']}s)\")\n                print(f\"   Source: {edu_acq.name}\")\n            else:\n                shutil.copy(edu_acq, label_file)\n                print(f\"‚úÖ Created Education label: {label_file.name} (duration={result['education_duration']}s)\")\n            status['education_created'] = True\n        else:\n            print(f\"‚ö†Ô∏è  No acq file found for Education duration {result['education_duration']}s\")\n\n    # Create SART practice label file\n    if result['sart_practice_duration']:\n        sart_prac_acq = find_acq_file_by_duration(subject_dir, result['sart_practice_duration'])\n        if sart_prac_acq:\n            session_id = sart_prac_acq.stem.split('_ses-')[1].split('_')[0]\n            label_file = subject_dir / f\"{subject_name}_ses-{session_id}_task-Video_label-SART-practice_haemo.csv\"\n\n            # Copy acq file to label file (or simulate in dry run)\n            if DRY_RUN:\n                print(f\"üîç [DRY RUN] Would create: {label_file.name} (duration={result['sart_practice_duration']}s)\")\n                print(f\"   Source: {sart_prac_acq.name}\")\n            else:\n                shutil.copy(sart_prac_acq, label_file)\n                print(f\"‚úÖ Created SART-practice label: {label_file.name} (duration={result['sart_practice_duration']}s)\")\n            status['sart_practice_created'] = True\n        else:\n            print(f\"‚ö†Ô∏è  No acq file found for SART practice duration {result['sart_practice_duration']}s\")\n\n    # Create SART actual label files (large unlabeled segments)\n    large_acq_files = find_large_unlabeled_acq_files(subject_dir)\n    if large_acq_files:\n        for i, large_acq in enumerate(large_acq_files):\n            # Parse duration\n            parts = large_acq.stem.split('_')\n            file_duration = None\n            for part in parts:\n                if part.startswith('dur-'):\n                    file_duration = int(part.split('-')[1])\n                    break\n\n            session_id = large_acq.stem.split('_ses-')[1].split('_')[0]\n\n            # If multiple large files, number them\n            if len(large_acq_files) > 1:\n                label_file = subject_dir / f\"{subject_name}_ses-{session_id}_task-Video_label-SART-actual-{i+1}_haemo.csv\"\n            else:\n                label_file = subject_dir / f\"{subject_name}_ses-{session_id}_task-Video_label-SART-actual_haemo.csv\"\n\n            # Copy acq file to label file (or simulate in dry run)\n            if DRY_RUN:\n                print(f\"üîç [DRY RUN] Would create: {label_file.name} (duration={file_duration}s)\")\n                print(f\"   Source: {large_acq.name}\")\n            else:\n                shutil.copy(large_acq, label_file)\n                print(f\"‚úÖ Created SART-actual label: {label_file.name} (duration={file_duration}s)\")\n            status['sart_actual_created'] = True\n    else:\n        print(f\"‚ÑπÔ∏è  No large unlabeled segments found (SART actual may be missing or mislabeled)\")\n\n    return status\n\n\n# Process all subjects\nsubject_dirs = sorted([d for d in preprocessed_dir.iterdir() if d.is_dir() and d.name.startswith('sub-')])\nprint(f\"Found {len(subject_dirs)} subjects\\n\")\n\nresults = []\nfor subject_dir in subject_dirs:\n    status = process_subject(subject_dir)\n    results.append(status)\n\nprint(f\"\\n{'='*60}\")\nprint(\"SUMMARY\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Summary Report\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\nTotal subjects processed: {len(results_df)}\")\n",
    "print(f\"Education labels created: {results_df['education_created'].sum()}\")\n",
    "print(f\"SART-practice labels created: {results_df['sart_practice_created'].sum()}\")\n",
    "print(f\"SART-actual labels created: {results_df['sart_actual_created'].sum()}\")\n",
    "\n",
    "# Subjects with warnings\n",
    "subjects_with_warnings = results_df[results_df['warnings'].apply(len) > 0]\n",
    "if len(subjects_with_warnings) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(subjects_with_warnings)} subjects with warnings:\")\n",
    "    for _, row in subjects_with_warnings.iterrows():\n",
    "        print(f\"  {row['subject']}: {row['warnings']}\")\n",
    "\n",
    "# Incomplete subjects\n",
    "incomplete = results_df[~results_df['education_created'] | ~results_df['sart_practice_created']]\n",
    "if len(incomplete) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(incomplete)} incomplete subjects (missing Education or SART-practice):\")\n",
    "    for _, row in incomplete.iterrows():\n",
    "        missing = []\n",
    "        if not row['education_created']:\n",
    "            missing.append('Education')\n",
    "        if not row['sart_practice_created']:\n",
    "            missing.append('SART-practice')\n",
    "        print(f\"  {row['subject']}: missing {', '.join(missing)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Relabeling complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}